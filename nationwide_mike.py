# -*- coding: utf-8 -*-
"""Nationwide_Mike.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19H1dbexvrBl0atOE_G7-L1fWfOABCivG
"""

# prompt: create a python script that splits a large CSV file "raw_data.csv" into six smaller pieces. Store the six files in a folder named chunks

import pandas as pd
import os

def split_csv(input_file, output_folder, num_chunks):
    """Splits a large CSV file into smaller chunks.

    Args:
        input_file: Path to the input CSV file.
        output_folder: Path to the folder where chunks will be stored.
        num_chunks: Number of chunks to split the file into.
    """

    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    try:
        df = pd.read_csv(input_file)
        chunk_size = len(df) // num_chunks

        for i in range(num_chunks):
            start = i * chunk_size
            end = (i + 1) * chunk_size if i < num_chunks - 1 else len(df)
            chunk = df[start:end]
            chunk.to_csv(os.path.join(output_folder, f"chunk_{i+1}.csv"), index=False)
        print(f"Successfully split '{input_file}' into {num_chunks} chunks in '{output_folder}'.")

    except Exception as e:
        print(f"An error occurred: {e}")

if __name__ == "__main__":
    input_file = "raw_data.csv"
    output_folder = "chunks"
    num_chunks = 6

    split_csv(input_file, output_folder, num_chunks)

# prompt: create a python script that translate the headers in a CSV file to English from Japanese. Run code for each file in chunks folder. Place the output files in a new folder

import pandas as pd
import os
from googletrans import Translator


def translate_headers(input_file, output_file):
    """Translates the headers of a CSV file from Japanese to English."""

    try:
        df = pd.read_csv(input_file)
        translator = Translator()
        new_headers = []
        for header in df.columns:
            try:
                translation = translator.translate(header, dest='en').text
                new_headers.append(translation)
            except Exception as e:
                print(f"Error translating '{header}': {e}")
                new_headers.append(header)

        df.columns = new_headers
        df.to_csv(output_file, index=False)
        print(f"Translated headers in '{input_file}' and saved to '{output_file}'.")

    except Exception as e:
        print(f"An error occurred: {e}")


if __name__ == "__main__":
    input_folder = "chunks"
    output_folder = "translated_chunks"

    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for filename in os.listdir(input_folder):
        if filename.endswith(".csv"):
            input_file = os.path.join(input_folder, filename)
            output_file = os.path.join(output_folder, filename)
            translate_headers(input_file, output_file)

# prompt: For each file in the translated_chunks folder, check for duplicates in the "Frame number", "ID card" and "Motor number" columns. for each duplicate found, keep the first record and remove the second record by placing it in a separate file called dump. Save the original files excluding the duplicates in a folder called cleaned chunks.

import pandas as pd
import os

def remove_duplicates(input_folder, output_folder, dump_folder):
  """Removes duplicate records based on specific columns and saves them to separate files."""
  if not os.path.exists(output_folder):
    os.makedirs(output_folder)

  if not os.path.exists(dump_folder):
    os.makedirs(dump_folder)

  for filename in os.listdir(input_folder):
    if filename.endswith(".csv"):
      input_file = os.path.join(input_folder, filename)
      output_file = os.path.join(output_folder, filename)
      dump_file = os.path.join(dump_folder, f"dump_{filename}")

      try:
        df = pd.read_csv(input_file)
        df_cleaned = df.drop_duplicates(subset=['Frame number', 'ID card', 'Motor number', 'Mail'], keep='first')
        df_duplicates = df[~df.index.isin(df_cleaned.index)]

        df_cleaned.to_csv(output_file, index=False)
        df_duplicates.to_csv(dump_file, index=False)
        print(f"Processed {filename}. Duplicates saved to {dump_file}, cleaned data saved to {output_file}.")

      except Exception as e:
        print(f"An error occurred while processing {filename}: {e}")


if __name__ == "__main__":
  input_folder = "translated_chunks"
  output_folder = "cleaned_chunks"
  dump_folder = "dump"

  remove_duplicates(input_folder, output_folder, dump_folder)

# prompt: for each file in the cleaned_chunks folder, check the "Mail" column for valid email addresses and remove all that are not valid. save the cleaned chunks in the cleaned_chunks folder All invalid emails should be saved in a folder call invalid. Do not include missing values in invalid

import pandas as pd
import os
import re

def is_valid_email(email):
  """Checks if an email address is valid."""
  if pd.isnull(email):
    return False
  pattern = r"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$"
  return bool(re.fullmatch(pattern, email))

def clean_email_chunks(input_folder, output_folder, invalid_folder):
  """Cleans email addresses in each chunk."""

  if not os.path.exists(output_folder):
    os.makedirs(output_folder)

  if not os.path.exists(invalid_folder):
    os.makedirs(invalid_folder)

  for filename in os.listdir(input_folder):
    if filename.endswith(".csv"):
      input_file = os.path.join(input_folder, filename)
      output_file = os.path.join(output_folder, filename)
      invalid_file = os.path.join(invalid_folder, f"invalid_{filename}")

      try:
        df = pd.read_csv(input_file)
        df_invalid = df[~df['Mail'].apply(is_valid_email)]
        df_invalid = df_invalid.dropna(subset=['Mail'])
        df_cleaned = df[df['Mail'].apply(is_valid_email)]


        df_cleaned.to_csv(output_file, index=False)
        df_invalid.to_csv(invalid_file, index=False)

        print(f"Processed {filename}. Invalid emails saved to {invalid_file}, cleaned data saved to {output_file}.")

      except Exception as e:
        print(f"An error occurred while processing {filename}: {e}")

if __name__ == "__main__":
  input_folder = "cleaned_chunks"
  output_folder = "cleaned_chunks"  # Overwrite the existing cleaned_chunks folder
  invalid_folder = "invalid"

  clean_email_chunks(input_folder, output_folder, invalid_folder)

# prompt: for file in cleaned_chunks drop the following columns : "gender", "industry","Monthly salary","marriage","educate"',"Unnamed: 21"

def drop_columns_in_chunks(input_folder, output_folder, columns_to_drop):
  """Drops specified columns from CSV files in a folder."""

  if not os.path.exists(output_folder):
    os.makedirs(output_folder)

  for filename in os.listdir(input_folder):
    if filename.endswith(".csv"):
      input_file = os.path.join(input_folder, filename)
      output_file = os.path.join(output_folder, filename)

      try:
        df = pd.read_csv(input_file)
        df_cleaned = df.drop(columns=columns_to_drop, errors='ignore')
        df_cleaned.to_csv(output_file, index=False)
        print(f"Processed {filename}. Dropped columns and saved to {output_file}.")

      except Exception as e:
        print(f"An error occurred while processing {filename}: {e}")


if __name__ == "__main__":
  input_folder = "cleaned_chunks"
  output_folder = "cleaned_chunks_final"
  columns_to_drop = ["gender", "industry", "Monthly salary", "marriage", "educate", "Unnamed: 21"]

  drop_columns_in_chunks(input_folder, output_folder, columns_to_drop)

# prompt: for file in cleaned_chunks_final, rename all headers so they are all lowercase and replace spaces with underscores

def rename_headers(input_folder, output_folder):
  """Renames headers in CSV files to lowercase and replaces spaces with underscores."""

  if not os.path.exists(output_folder):
    os.makedirs(output_folder)

  for filename in os.listdir(input_folder):
    if filename.endswith(".csv"):
      input_file = os.path.join(input_folder, filename)
      output_file = os.path.join(output_folder, filename)

      try:
        df = pd.read_csv(input_file)
        new_headers = [header.lower().replace(" ", "_") for header in df.columns]
        df.columns = new_headers
        df.to_csv(output_file, index=False)
        print(f"Processed {filename}. Renamed headers and saved to {output_file}.")

      except Exception as e:
        print(f"An error occurred while processing {filename}: {e}")

if __name__ == "__main__":
  input_folder = "cleaned_chunks_final"
  output_folder = "cleaned_chunks_final"  # Overwrite the existing folder

  rename_headers(input_folder, output_folder)

# prompt: for file in cleaned_chunks_final, Merge all of the files into one CSV file. name the the file cleaned_data

import pandas as pd
import os

def merge_csv_files(input_folder, output_file):
  """Merges all CSV files in a folder into a single CSV file."""

  all_dataframes = []
  for filename in os.listdir(input_folder):
    if filename.endswith(".csv"):
      file_path = os.path.join(input_folder, filename)
      try:
        df = pd.read_csv(file_path)
        all_dataframes.append(df)
      except Exception as e:
        print(f"Error reading {filename}: {e}")

  if all_dataframes:
    merged_df = pd.concat(all_dataframes, ignore_index=True)
    merged_df.to_csv(output_file, index=False)
    print(f"Merged CSV files from '{input_folder}' into '{output_file}'.")
  else:
    print(f"No CSV files found in '{input_folder}'.")


if __name__ == "__main__":
  input_folder = "cleaned_chunks_final"
  output_file = "cleaned_data.csv"

  merge_csv_files(input_folder, output_file)

dataset=pd.read_csv("cleaned_data.csv")
dataset.head()

# prompt: for file in cleaned_chunks_final, Merge all of the files into one CSV file. name the the file cleaned_data

import pandas as pd
import os

def merge_csv_files(input_folder, output_file):
  """Merges all CSV files in a folder into a single CSV file."""

  all_dataframes = []
  for filename in os.listdir(input_folder):
    if filename.endswith(".csv"):
      file_path = os.path.join(input_folder, filename)
      try:
        df = pd.read_csv(file_path)
        all_dataframes.append(df)
      except Exception as e:
        print(f"Error reading {filename}: {e}")

  if all_dataframes:
    merged_df = pd.concat(all_dataframes, ignore_index=True)
    merged_df.to_csv(output_file, index=False)
    print(f"Merged CSV files from '{input_folder}' into '{output_file}'.")
  else:
    print(f"No CSV files found in '{input_folder}'.")


if __name__ == "__main__":
  input_folder = "invalid"
  output_file = "invalid_emails.csv"

  merge_csv_files(input_folder, output_file)